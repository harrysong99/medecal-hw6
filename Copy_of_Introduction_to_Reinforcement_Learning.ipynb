{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of Introduction to Reinforcement Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA06qjBYnYNi"
      },
      "source": [
        "# Reinforcement Learning Homework\n",
        "\n",
        "Reinforcement learning (RL) is interested in how we can design algorithms that get better at making decisions in dynamic environments. In this homework, we'll focus on **policy gradient** algorithms. Reinforcement learning contains a plethora of algorithm components and types, but the policy gradient family is easier to explain and get some intuition on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK0yCGnonYNk"
      },
      "source": [
        "## Policy Gradient\n",
        "\n",
        "The idea behind policy gradient is similar to how you would approach learning any new skill like riding a bike, baking a cake, etc. You try out some actions based on what you think is most likely to work, you reflect a little bit on what you're lacking or could improve on, and you try again. In short, trial and error. To make this work as an algorithm, we need to start specifying some components.\n",
        "\n",
        "Recall that the **policy** is the agent's decision making strategy, often modeled as a probability distribution which we label $\\pi$. We might write the joint distribution $\\pi(s, a)$ or a conditional distribution $\\pi(a \\mid s)$. In either case, the policy is the answer the question, \"If you, the agent, were in scenario $s$, how likely are you to take action $a$?\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9DdqIu0nYNm"
      },
      "source": [
        "If we model the policy as a neural network, then there's a direct connection between the weights of the neural network and how well the policy performs. Our goal is to then determine a way by which we can tweak the weights to improve performance.\n",
        "\n",
        "In supervised learning, we have the idea of **gradient descent** as a way to improve a model's performance on a classification or regression task by modifying the weights to lower some measure of model error. We can apply the exact same idea and strategy but it requires us to create a measure of performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3rkrVuonYNn"
      },
      "source": [
        "## Proximal Policy Optimization (PPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrTm65txnYNo"
      },
      "source": [
        "In this homework, we'll be looking at an instantiation of policy gradient called [Proximal Policy Optimization](https://openai.com/blog/openai-baselines-ppo/). The paper is [here](https://arxiv.org/pdf/1707.06347.pdf) -- part of your assignment is to read or at least fully skim it.\n",
        "\n",
        "\n",
        "The idea in this paper is to introduce a slightly different objective; figuring out the reasoning behind this change is part of your assignment, but the paper explains why they make this change. The objective that they are deviating from looks like\n",
        "\n",
        "$$\n",
        "L^{CPI}(\\theta) = \\hat{\\mathbb{E}}_t\\left[\\frac{\\pi_\\theta(a_t \\mid s_t) }{ \\pi_{\\theta_{old}}(a_t \\mid s_t) } \\hat{A}_t \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqypKJ21nYNo"
      },
      "source": [
        "The $\\hat{\\mathbb{E}}_t$ represents an empirical expectation (i.e. an average that we will compute) over time. $\\theta$ represents weights of the neural network so that $\\theta_{old}$ are the weights we would like to improve upon. $\\hat{A}_t$ represents the **advantage** over time. \n",
        "\n",
        "The advantage $A$ is a numerical score assigned to state-action pairs $(s, a)$. If you want a little mathematical notation to go with that,\n",
        "\n",
        "$$\n",
        "A: \\mathcal{S}\\times\\mathcal{A} \\to \\mathbb{R}.\n",
        "$$\n",
        "\n",
        "The advantage's job is to say how good it is to be in a certain state taking a certain action. We won't go into how it's computed, but just know that if somebody gave you a record of all the states they encountered, actions they took, and rewards they achieved, that would be enough to compute the advantage. The purpose of introducing an advantage function is to make it easy to identify which state-action pairs we should focus on making more likely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGM6AHpYnYNp"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "This assignment will be fairly gentle since next week's homework is also about RL. The idea is just to get you accustomed to thinking about the objects and data structures we need to do RL.\n",
        "\n",
        "## Task 1\n",
        "\n",
        "Please read [this brief documentation](https://gym.openai.com/docs/) about OpenAI Gym, which provides lots of environments to test RL algorithms. Here are two questions to figure out during/after reading:\n",
        "\n",
        "1. Assume you have an action that you want to take (for example, you might call `sample` from the `env.action_space` to get a uniformly random action). How do you actually take this action in the environment? What method do you call on the `env`?\n",
        "2. How do you reset an environment? What information does the reset return?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7g7B8rlnYNp"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "First, we will import some libraries. We will need to install OpenAI `spinningup`, but this has to be done by cloning their repo. You might want to delete this cell after the first time you run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly9poH7anfZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90349c4d-1666-444b-8bf8-1e9262c7f77f"
      },
      "source": [
        "!git clone https://github.com/openai/spinningup\n",
        "!cd spinningup\n",
        "!pip install -e spinningup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'spinningup' already exists and is not an empty directory.\n",
            "Obtaining file:///content/spinningup\n",
            "Requirement already satisfied: cloudpickle==1.2.1 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.2.1)\n",
            "Requirement already satisfied: gym[atari,box2d,classic_control]~=0.15.3 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (0.15.7)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (5.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (0.17.0)\n",
            "Requirement already satisfied: matplotlib==3.1.1 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.1.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (3.6.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (5.4.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.4.1)\n",
            "Requirement already satisfied: seaborn==0.8.1 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow<2.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.15.4)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from spinup==0.2.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (0.2.6)\n",
            "Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (7.0.0)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (2.3.8)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (50.3.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->spinup==0.2.0) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->spinup==0.2.0) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->spinup==0.2.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->spinup==0.2.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.1.1->spinup==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->spinup==0.2.0) (2018.9)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spinup==0.2.0) (8.6.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->spinup==0.2.0) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spinup==0.2.0) (20.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spinup==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->spinup==0.2.0) (1.4.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.33.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.15.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (0.35.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.0,>=1.8.0->spinup==0.2.0) (0.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,box2d,classic_control]~=0.15.3->spinup==0.2.0) (0.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->spinup==0.2.0) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->spinup==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->spinup==0.2.0) (0.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2.0,>=1.8.0->spinup==0.2.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.8.0->spinup==0.2.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.8.0->spinup==0.2.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.8.0->spinup==0.2.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<2.0,>=1.8.0->spinup==0.2.0) (3.4.0)\n",
            "Installing collected packages: spinup\n",
            "  Found existing installation: spinup 0.2.0\n",
            "    Can't uninstall 'spinup'. No files were found to uninstall.\n",
            "  Running setup.py develop for spinup\n",
            "Successfully installed spinup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4aZDUVf5XPo"
      },
      "source": [
        "You may need to restart the Colab kernel (Runtime > restart runtime) for spinup to become part of the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psjgXA_jnYNq"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import gym\n",
        "import time\n",
        "import spinup.algos.pytorch.ppo.core as core\n",
        "from spinup.utils.logx import EpochLogger\n",
        "from spinup.utils.mpi_pytorch import setup_pytorch_for_mpi, sync_params, mpi_avg_grads\n",
        "from spinup.utils.mpi_tools import mpi_fork, mpi_avg, proc_id, mpi_statistics_scalar, num_procs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLKU1fWxnYNy"
      },
      "source": [
        "Most RL algorithms use a buffer data structure to record the information from trial episodes. Take a look at the methods to get a sense for what this buffer does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cb083hrnYNy"
      },
      "source": [
        "class PPOBuffer:\n",
        "    def __init__(self, obs_dim, act_dim, size, gamma=0.99, lam=0.95):\n",
        "        self.obs_buf = np.zeros(core.combined_shape(size, obs_dim), dtype=np.float32)\n",
        "        self.act_buf = np.zeros(core.combined_shape(size, act_dim), dtype=np.float32)\n",
        "        self.adv_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.ret_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.val_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.logp_buf = np.zeros(size, dtype=np.float32)\n",
        "        self.gamma, self.lam = gamma, lam\n",
        "        self.ptr, self.path_start_idx, self.max_size = 0, 0, size\n",
        "\n",
        "    def store(self, obs, act, rew, val, logp):\n",
        "        \"\"\"\n",
        "        Append one timestep of agent-environment interaction to the buffer.\n",
        "        \"\"\"\n",
        "        assert self.ptr < self.max_size     # buffer has to have room so you can store\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.act_buf[self.ptr] = act\n",
        "        self.rew_buf[self.ptr] = rew\n",
        "        self.val_buf[self.ptr] = val\n",
        "        self.logp_buf[self.ptr] = logp\n",
        "        self.ptr += 1\n",
        "\n",
        "    def finish_path(self, last_val=0):\n",
        "        \"\"\"\n",
        "        Call this at the end of a trajectory, or when one gets cut off\n",
        "        by an epoch ending. This looks back in the buffer to where the\n",
        "        trajectory started, and uses rewards and value estimates from\n",
        "        the whole trajectory to compute advantage estimates with GAE-Lambda,\n",
        "        as well as compute the rewards-to-go for each state, to use as\n",
        "        the targets for the value function.\n",
        "        The \"last_val\" argument should be 0 if the trajectory ended\n",
        "        because the agent reached a terminal state (died), and otherwise\n",
        "        should be V(s_T), the value function estimated for the last state.\n",
        "        This allows us to bootstrap the reward-to-go calculation to account\n",
        "        for timesteps beyond the arbitrary episode horizon (or epoch cutoff).\n",
        "        \"\"\"\n",
        "\n",
        "        path_slice = slice(self.path_start_idx, self.ptr)\n",
        "        rews = np.append(self.rew_buf[path_slice], last_val)\n",
        "        vals = np.append(self.val_buf[path_slice], last_val)\n",
        "        \n",
        "        # the next two lines implement GAE-Lambda advantage calculation\n",
        "        deltas = rews[:-1] + self.gamma * vals[1:] - vals[:-1]\n",
        "        self.adv_buf[path_slice] = core.discount_cumsum(deltas, self.gamma * self.lam)\n",
        "        \n",
        "        # the next line computes rewards-to-go, to be targets for the value function\n",
        "        self.ret_buf[path_slice] = core.discount_cumsum(rews, self.gamma)[:-1]\n",
        "        \n",
        "        self.path_start_idx = self.ptr\n",
        "\n",
        "    def get(self):\n",
        "        \"\"\"\n",
        "        Call this at the end of an epoch to get all of the data from\n",
        "        the buffer, with advantages appropriately normalized (shifted to have\n",
        "        mean zero and std one). Also, resets some pointers in the buffer.\n",
        "        \"\"\"\n",
        "        assert self.ptr == self.max_size    # buffer has to be full before you can get\n",
        "        self.ptr, self.path_start_idx = 0, 0\n",
        "        # the next two lines implement the advantage normalization trick\n",
        "        adv_mean, adv_std = mpi_statistics_scalar(self.adv_buf)\n",
        "        self.adv_buf = (self.adv_buf - adv_mean) / adv_std\n",
        "        data = dict(obs=self.obs_buf, act=self.act_buf, ret=self.ret_buf,\n",
        "                    adv=self.adv_buf, logp=self.logp_buf)\n",
        "        return {k: torch.as_tensor(v, dtype=torch.float32) for k,v in data.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj9vMhWOnYN4"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Okay, here's the part where you will start implementing things. There are two losses that you need to have.\n",
        "\n",
        "1. A loss for the policy. We are implementing policy gradient after all.\n",
        "2. A loss for the **value function**, which is related to the advantage function. \n",
        "\n",
        "The difference is that value is a function of state only whereas advantage is a function of both state and action. Again, you don't need to worry about the details of how value is computed. \n",
        "\n",
        "First, we'll walk through implementing the policy loss. This is Equation 7 in the paper. A few important notes to consider:\n",
        "\n",
        "* The way this code is structured, we use the [log of probability](https://en.wikipedia.org/wiki/Log_probability), which can be more stable than probabilities, which have to be in the $[0,1]$ interval. So if you want to compute $r_t = \\frac{\\pi(a \\mid s)}{ \\pi_{\\text{old}}(a \\mid s) }$ but you only have access to $\\log \\pi (a \\mid s)$ and $\\log \\pi_{\\text{old}}(a \\mid s)$, what do you do? In the code block below, put this value into the `ratio` variable using only 1 call to `torch.exp`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OTFE8SJnYN5"
      },
      "source": [
        "def your_policy_loss(ac, obs, act, adv, logp_old, epsilon):\n",
        "    pi, logp = ac.pi(obs, act)\n",
        "    ratio    = torch.exp(logp-logp_old) # TODO compute the ratio using log probs and 1 call to torch.exp\n",
        "    clip_adv = torch.clamp(ratio, 1-epsilon, 1+epsilon) * adv # TODO appropriately clip the ratio and multiply it by the advantage. Use torch.clamp to clip.\n",
        "    loss_pi  = -torch.min(clip_adv, ratio*adv).mean() # TODO find the mean of the minimum of clip_adv and ratio * adv. Hint: use torch.min and then call .mean() on the result\n",
        "    \n",
        "    # NOTE make sure to put a negative sign in front of the loss because pytorch tries to maximize, not minimize, by default.\n",
        "\n",
        "    return pi, ratio, loss_pi, logp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSRR3fTcnYN7"
      },
      "source": [
        "The value function is represented by a neural network too, but we have the supervision for it! Write a mean squared error loss for the value assigned to a state/observation if the correct value is `ret`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMeC4bKqnYN8"
      },
      "source": [
        "def your_value_loss(ac, obs, ret):\n",
        "    value_fn = ac.v\n",
        "    value = value_fn(obs) # TODO compute the value of obs\n",
        "    return ((value-ret)**2).mean() # TODO square the difference between value and ret and call .mean() on that value."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puQPPH02nYN-"
      },
      "source": [
        "def ppo(env_fn, actor_critic=core.MLPActorCritic, ac_kwargs=dict(), seed=0, \n",
        "        steps_per_epoch=4000, epochs=50, gamma=0.99, clip_ratio=0.2, pi_lr=3e-4,\n",
        "        vf_lr=1e-3, train_pi_iters=80, train_v_iters=80, lam=0.97, max_ep_len=1000,\n",
        "        target_kl=0.01, logger_kwargs=dict(), save_freq=10):\n",
        "    \"\"\"\n",
        "    Proximal Policy Optimization (by clipping), \n",
        "    with early stopping based on approximate KL\n",
        "    Args:\n",
        "        env_fn : A function which creates a copy of the environment.\n",
        "            The environment must satisfy the OpenAI Gym API.\n",
        "        actor_critic: The constructor method for a PyTorch Module with a \n",
        "            ``step`` method, an ``act`` method, a ``pi`` module, and a ``v`` \n",
        "            module. The ``step`` method should accept a batch of observations \n",
        "            and return:\n",
        "            ===========  ================  ======================================\n",
        "            Symbol       Shape             Description\n",
        "            ===========  ================  ======================================\n",
        "            ``a``        (batch, act_dim)  | Numpy array of actions for each \n",
        "                                           | observation.\n",
        "            ``v``        (batch,)          | Numpy array of value estimates\n",
        "                                           | for the provided observations.\n",
        "            ``logp_a``   (batch,)          | Numpy array of log probs for the\n",
        "                                           | actions in ``a``.\n",
        "            ===========  ================  ======================================\n",
        "            The ``act`` method behaves the same as ``step`` but only returns ``a``.\n",
        "            The ``pi`` module's forward call should accept a batch of \n",
        "            observations and optionally a batch of actions, and return:\n",
        "            ===========  ================  ======================================\n",
        "            Symbol       Shape             Description\n",
        "            ===========  ================  ======================================\n",
        "            ``pi``       N/A               | Torch Distribution object, containing\n",
        "                                           | a batch of distributions describing\n",
        "                                           | the policy for the provided observations.\n",
        "            ``logp_a``   (batch,)          | Optional (only returned if batch of\n",
        "                                           | actions is given). Tensor containing \n",
        "                                           | the log probability, according to \n",
        "                                           | the policy, of the provided actions.\n",
        "                                           | If actions not given, will contain\n",
        "                                           | ``None``.\n",
        "            ===========  ================  ======================================\n",
        "            The ``v`` module's forward call should accept a batch of observations\n",
        "            and return:\n",
        "            ===========  ================  ======================================\n",
        "            Symbol       Shape             Description\n",
        "            ===========  ================  ======================================\n",
        "            ``v``        (batch,)          | Tensor containing the value estimates\n",
        "                                           | for the provided observations. (Critical: \n",
        "                                           | make sure to flatten this!)\n",
        "            ===========  ================  ======================================\n",
        "        ac_kwargs (dict): Any kwargs appropriate for the ActorCritic object \n",
        "            you provided to PPO.\n",
        "        seed (int): Seed for random number generators.\n",
        "        steps_per_epoch (int): Number of steps of interaction (state-action pairs) \n",
        "            for the agent and the environment in each epoch.\n",
        "        epochs (int): Number of epochs of interaction (equivalent to\n",
        "            number of policy updates) to perform.\n",
        "        gamma (float): Discount factor. (Always between 0 and 1.)\n",
        "        clip_ratio (float): Hyperparameter for clipping in the policy objective.\n",
        "            Roughly: how far can the new policy go from the old policy while \n",
        "            still profiting (improving the objective function)? The new policy \n",
        "            can still go farther than the clip_ratio says, but it doesn't help\n",
        "            on the objective anymore. (Usually small, 0.1 to 0.3.) Typically\n",
        "            denoted by :math:`\\epsilon`. \n",
        "        pi_lr (float): Learning rate for policy optimizer.\n",
        "        vf_lr (float): Learning rate for value function optimizer.\n",
        "        train_pi_iters (int): Maximum number of gradient descent steps to take \n",
        "            on policy loss per epoch. (Early stopping may cause optimizer\n",
        "            to take fewer than this.)\n",
        "        train_v_iters (int): Number of gradient descent steps to take on \n",
        "            value function per epoch.\n",
        "        lam (float): Lambda for GAE-Lambda. (Always between 0 and 1,\n",
        "            close to 1.)\n",
        "        max_ep_len (int): Maximum length of trajectory / episode / rollout.\n",
        "        target_kl (float): Roughly what KL divergence we think is appropriate\n",
        "            between new and old policies after an update. This will get used \n",
        "            for early stopping. (Usually small, 0.01 or 0.05.)\n",
        "        logger_kwargs (dict): Keyword args for EpochLogger.\n",
        "        save_freq (int): How often (in terms of gap between epochs) to save\n",
        "            the current policy and value function.\n",
        "    \"\"\"\n",
        "\n",
        "    # Special function to avoid certain slowdowns from PyTorch + MPI combo.\n",
        "    setup_pytorch_for_mpi()\n",
        "\n",
        "    # Set up logger and save configuration\n",
        "    logger = EpochLogger(**logger_kwargs)\n",
        "    logger.save_config(locals())\n",
        "\n",
        "    # Random seed\n",
        "    seed += 10000 * proc_id()\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Instantiate environment\n",
        "    env = env_fn()\n",
        "    obs_dim = env.observation_space.shape\n",
        "    act_dim = env.action_space.shape\n",
        "\n",
        "    # Create actor-critic module\n",
        "    ac = actor_critic(env.observation_space, env.action_space, **ac_kwargs)\n",
        "\n",
        "    # Sync params across processes\n",
        "    sync_params(ac)\n",
        "\n",
        "    # Count variables\n",
        "    var_counts = tuple(core.count_vars(module) for module in [ac.pi, ac.v])\n",
        "    logger.log('\\nNumber of parameters: \\t pi: %d, \\t v: %d\\n'%var_counts)\n",
        "\n",
        "    # Set up experience buffer\n",
        "    local_steps_per_epoch = int(steps_per_epoch / num_procs())\n",
        "    buf = PPOBuffer(obs_dim, act_dim, local_steps_per_epoch, gamma, lam)\n",
        "    \n",
        "    def compute_loss_pi(data):\n",
        "        obs, act, adv, logp_old = data['obs'], data['act'], data['adv'], data['logp']\n",
        "\n",
        "        # Policy loss\n",
        "        pi, ratio, loss_pi, logp = your_policy_loss(ac, obs, act, adv, logp_old, clip_ratio)\n",
        "\n",
        "        # Useful extra info\n",
        "        approx_kl = (logp_old - logp).mean().item()\n",
        "        ent = pi.entropy().mean().item()\n",
        "        clipped = ratio.gt(1+clip_ratio) | ratio.lt(1-clip_ratio)\n",
        "        clipfrac = torch.as_tensor(clipped, dtype=torch.float32).mean().item()\n",
        "        pi_info = dict(kl=approx_kl, ent=ent, cf=clipfrac)\n",
        "\n",
        "        return loss_pi, pi_info\n",
        "\n",
        "    def compute_loss_v(data):\n",
        "        obs, ret = data['obs'], data['ret']\n",
        "        return your_value_loss(ac, obs, ret)\n",
        "\n",
        "    # Set up optimizers for policy and value function\n",
        "    pi_optimizer = Adam(ac.pi.parameters(), lr=pi_lr)\n",
        "    vf_optimizer = Adam(ac.v.parameters(), lr=vf_lr)\n",
        "\n",
        "    # Set up model saving\n",
        "    logger.setup_pytorch_saver(ac)\n",
        "    \n",
        "    def mystery():\n",
        "        data = buf.get()\n",
        "\n",
        "        pi_l_old, pi_info_old = compute_loss_pi(data)\n",
        "        pi_l_old = pi_l_old.item()\n",
        "        v_l_old = compute_loss_v(data).item()\n",
        "\n",
        "        for i in range(train_pi_iters):\n",
        "            pi_optimizer.zero_grad()\n",
        "            loss_pi, pi_info = compute_loss_pi(data)\n",
        "            kl = mpi_avg(pi_info['kl'])\n",
        "            if kl > 1.5 * target_kl:\n",
        "                logger.log('Early stopping at step %d due to reaching max kl.'%i)\n",
        "                break\n",
        "            loss_pi.backward()\n",
        "            mpi_avg_grads(ac.pi)\n",
        "            pi_optimizer.step()\n",
        "\n",
        "        logger.store(StopIter=i)\n",
        "\n",
        "        for i in range(train_v_iters):\n",
        "            vf_optimizer.zero_grad()\n",
        "            loss_v = compute_loss_v(data)\n",
        "            loss_v.backward()\n",
        "            mpi_avg_grads(ac.v)\n",
        "            vf_optimizer.step()\n",
        "\n",
        "        kl, ent, cf = pi_info['kl'], pi_info_old['ent'], pi_info['cf']\n",
        "        logger.store(LossPi=pi_l_old, LossV=v_l_old,\n",
        "                     KL=kl, Entropy=ent, ClipFrac=cf,\n",
        "                     DeltaLossPi=(loss_pi.item() - pi_l_old),\n",
        "                     DeltaLossV=(loss_v.item() - v_l_old))\n",
        "    \n",
        "    # Prepare for interaction with environment\n",
        "    start_time = time.time()\n",
        "    o = env.reset()\n",
        "    ep_ret = 0\n",
        "    ep_len = 0\n",
        "\n",
        "    # Main loop: collect experience in env and update/log each epoch\n",
        "    for epoch in range(epochs):\n",
        "        for t in range(local_steps_per_epoch):\n",
        "            a, v, logp = ac.step(torch.as_tensor(o, dtype=torch.float32))\n",
        "            \n",
        "            # TODO how do we take an action in the environment\n",
        "            # ===============================\n",
        "            f = env.step\n",
        "            # ===============================\n",
        "            \n",
        "            next_o, r, d, _ = f(a)\n",
        "            ep_ret += r\n",
        "            ep_len += 1\n",
        "\n",
        "            # save and log\n",
        "            buf.store(o, a, r, v, logp)\n",
        "            logger.store(VVals=v)\n",
        "            \n",
        "            # Update obs (critical!)\n",
        "            o = next_o\n",
        "\n",
        "            timeout = ep_len == max_ep_len\n",
        "            terminal = d or timeout\n",
        "            epoch_ended = t==local_steps_per_epoch-1\n",
        "\n",
        "            if terminal or epoch_ended:\n",
        "                if epoch_ended and not(terminal):\n",
        "                    print('Warning: trajectory cut off by epoch at %d steps.'%ep_len, flush=True)\n",
        "                # if trajectory didn't reach terminal state, bootstrap value target\n",
        "                if timeout or epoch_ended:\n",
        "                    _, v, _ = ac.step(torch.as_tensor(o, dtype=torch.float32))\n",
        "                else:\n",
        "                    v = 0\n",
        "                buf.finish_path(v)\n",
        "                if terminal:\n",
        "                    # only save EpRet / EpLen if trajectory finished\n",
        "                    logger.store(EpRet=ep_ret, EpLen=ep_len)\n",
        "\n",
        "                o = env.reset()\n",
        "                ep_ret = 0\n",
        "                ep_len = 0\n",
        "\n",
        "\n",
        "        # Save model\n",
        "        if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
        "            logger.save_state({'env': env}, None)\n",
        "\n",
        "        mystery()\n",
        "\n",
        "        # Log info about epoch\n",
        "        logger.log_tabular('Epoch', epoch)\n",
        "        logger.log_tabular('EpRet', with_min_and_max=True)\n",
        "        logger.log_tabular('EpLen', average_only=True)\n",
        "        logger.log_tabular('VVals', with_min_and_max=True)\n",
        "        logger.log_tabular('TotalEnvInteracts', (epoch+1)*steps_per_epoch)\n",
        "        logger.log_tabular('LossPi', average_only=True)\n",
        "        logger.log_tabular('LossV', average_only=True)\n",
        "        logger.log_tabular('DeltaLossPi', average_only=True)\n",
        "        logger.log_tabular('DeltaLossV', average_only=True)\n",
        "        logger.log_tabular('Entropy', average_only=True)\n",
        "        logger.log_tabular('KL', average_only=True)\n",
        "        logger.log_tabular('ClipFrac', average_only=True)\n",
        "        logger.log_tabular('StopIter', average_only=True)\n",
        "        logger.log_tabular('Time', time.time()-start_time)\n",
        "        logger.dump_tabular()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdx-Qe63nYOC"
      },
      "source": [
        "Run your algorithm! You're not expected to show that you can solve the environment, but the goal of this assignment is to see a cool example of RL so run this for as long as is feasible for you. I picked two simple environments to play around with: Cart Pole and Lunar Lander. Lunar Lander needs about 60 epochs before you see reasonable behavior, CartPole only needs 20 or so. Feel free to look at Gym for more environments, your only task is to comment on the behavior you see for whatever environment you pick."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBeAUCj5nYOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f46fa5-4879-45ab-bedb-760d3e335e26"
      },
      "source": [
        "env_fn = lambda : gym.make('CartPole-v1')\n",
        "env_fn = lambda : gym.make('LunarLander-v2')\n",
        "\n",
        "ac_kwargs = dict(\n",
        "        hidden_sizes=[64,64],\n",
        "        activation=torch.nn.ReLU,\n",
        "        )\n",
        "\n",
        "logger_kwargs = dict(output_dir='./output/', exp_name='my-first-rl-experiment')\n",
        "\n",
        "ppo(env_fn=env_fn, ac_kwargs=ac_kwargs, steps_per_epoch=5000, epochs=60, logger_kwargs=logger_kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Log dir ./output/ already exists! Storing info there anyway.\n",
            "\u001b[32;1mLogging data to ./output/progress.txt\u001b[0m\n",
            "\u001b[36;1mSaving config:\n",
            "\u001b[0m\n",
            "{\n",
            "    \"ac_kwargs\":\t{\n",
            "        \"activation\":\t\"ReLU\",\n",
            "        \"hidden_sizes\":\t[\n",
            "            64,\n",
            "            64\n",
            "        ]\n",
            "    },\n",
            "    \"actor_critic\":\t\"MLPActorCritic\",\n",
            "    \"clip_ratio\":\t0.2,\n",
            "    \"env_fn\":\t\"<function <lambda> at 0x7f46a85831e0>\",\n",
            "    \"epochs\":\t60,\n",
            "    \"exp_name\":\t\"my-first-rl-experiment\",\n",
            "    \"gamma\":\t0.99,\n",
            "    \"lam\":\t0.97,\n",
            "    \"logger\":\t{\n",
            "        \"<spinup.utils.logx.EpochLogger object at 0x7f46a2b2e630>\":\t{\n",
            "            \"epoch_dict\":\t{},\n",
            "            \"exp_name\":\t\"my-first-rl-experiment\",\n",
            "            \"first_row\":\ttrue,\n",
            "            \"log_current_row\":\t{},\n",
            "            \"log_headers\":\t[],\n",
            "            \"output_dir\":\t\"./output/\",\n",
            "            \"output_file\":\t{\n",
            "                \"<_io.TextIOWrapper name='./output/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
            "                    \"mode\":\t\"w\"\n",
            "                }\n",
            "            }\n",
            "        }\n",
            "    },\n",
            "    \"logger_kwargs\":\t{\n",
            "        \"exp_name\":\t\"my-first-rl-experiment\",\n",
            "        \"output_dir\":\t\"./output/\"\n",
            "    },\n",
            "    \"max_ep_len\":\t1000,\n",
            "    \"pi_lr\":\t0.0003,\n",
            "    \"save_freq\":\t10,\n",
            "    \"seed\":\t0,\n",
            "    \"steps_per_epoch\":\t5000,\n",
            "    \"target_kl\":\t0.01,\n",
            "    \"train_pi_iters\":\t80,\n",
            "    \"train_v_iters\":\t80,\n",
            "    \"vf_lr\":\t0.001\n",
            "}\n",
            "\u001b[32;1m\n",
            "Number of parameters: \t pi: 4996, \t v: 4801\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: trajectory cut off by epoch at 61 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               0 |\n",
            "|      AverageEpRet |            -201 |\n",
            "|          StdEpRet |             114 |\n",
            "|          MaxEpRet |           -75.8 |\n",
            "|          MinEpRet |            -496 |\n",
            "|             EpLen |            93.2 |\n",
            "|      AverageVVals |          -0.154 |\n",
            "|          StdVVals |          0.0497 |\n",
            "|          MaxVVals |           -0.07 |\n",
            "|          MinVVals |          -0.447 |\n",
            "| TotalEnvInteracts |           5e+03 |\n",
            "|            LossPi |        6.36e-08 |\n",
            "|             LossV |        1.51e+04 |\n",
            "|       DeltaLossPi |         -0.0147 |\n",
            "|        DeltaLossV |       -2.85e+03 |\n",
            "|           Entropy |            1.38 |\n",
            "|                KL |          0.0115 |\n",
            "|          ClipFrac |           0.126 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            4.97 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 109 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               1 |\n",
            "|      AverageEpRet |            -135 |\n",
            "|          StdEpRet |            60.8 |\n",
            "|          MaxEpRet |           -60.3 |\n",
            "|          MinEpRet |            -350 |\n",
            "|             EpLen |            88.9 |\n",
            "|      AverageVVals |             -14 |\n",
            "|          StdVVals |            3.04 |\n",
            "|          MaxVVals |           -7.09 |\n",
            "|          MinVVals |           -33.1 |\n",
            "| TotalEnvInteracts |           1e+04 |\n",
            "|            LossPi |        1.14e-08 |\n",
            "|             LossV |        4.96e+03 |\n",
            "|       DeltaLossPi |         -0.0193 |\n",
            "|        DeltaLossV |        -3.8e+03 |\n",
            "|           Entropy |            1.38 |\n",
            "|                KL |          0.0127 |\n",
            "|          ClipFrac |            0.14 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            9.96 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 21 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               2 |\n",
            "|      AverageEpRet |            -119 |\n",
            "|          StdEpRet |            71.7 |\n",
            "|          MaxEpRet |           -15.4 |\n",
            "|          MinEpRet |            -400 |\n",
            "|             EpLen |            97.6 |\n",
            "|      AverageVVals |           -66.2 |\n",
            "|          StdVVals |            11.6 |\n",
            "|          MaxVVals |           -35.7 |\n",
            "|          MinVVals |            -185 |\n",
            "| TotalEnvInteracts |         1.5e+04 |\n",
            "|            LossPi |        3.22e-09 |\n",
            "|             LossV |        1.73e+03 |\n",
            "|       DeltaLossPi |         -0.0183 |\n",
            "|        DeltaLossV |            -341 |\n",
            "|           Entropy |            1.37 |\n",
            "|                KL |          0.0143 |\n",
            "|          ClipFrac |           0.144 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |              15 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 88 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               3 |\n",
            "|      AverageEpRet |            -135 |\n",
            "|          StdEpRet |            75.6 |\n",
            "|          MaxEpRet |           -35.4 |\n",
            "|          MinEpRet |            -303 |\n",
            "|             EpLen |            98.2 |\n",
            "|      AverageVVals |           -64.2 |\n",
            "|          StdVVals |            7.76 |\n",
            "|          MaxVVals |           -39.6 |\n",
            "|          MinVVals |            -160 |\n",
            "| TotalEnvInteracts |           2e+04 |\n",
            "|            LossPi |       -2.21e-09 |\n",
            "|             LossV |        1.98e+03 |\n",
            "|       DeltaLossPi |         -0.0181 |\n",
            "|        DeltaLossV |            -345 |\n",
            "|           Entropy |            1.35 |\n",
            "|                KL |          0.0136 |\n",
            "|          ClipFrac |           0.118 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            20.3 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 12 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               4 |\n",
            "|      AverageEpRet |           -80.3 |\n",
            "|          StdEpRet |            47.8 |\n",
            "|          MaxEpRet |           -11.2 |\n",
            "|          MinEpRet |            -233 |\n",
            "|             EpLen |             111 |\n",
            "|      AverageVVals |           -72.7 |\n",
            "|          StdVVals |            11.1 |\n",
            "|          MaxVVals |           -27.1 |\n",
            "|          MinVVals |            -200 |\n",
            "| TotalEnvInteracts |         2.5e+04 |\n",
            "|            LossPi |       -1.83e-08 |\n",
            "|             LossV |        2.19e+03 |\n",
            "|       DeltaLossPi |         -0.0166 |\n",
            "|        DeltaLossV |       -1.13e+03 |\n",
            "|           Entropy |            1.32 |\n",
            "|                KL |         0.00833 |\n",
            "|          ClipFrac |           0.173 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            26.5 |\n",
            "---------------------------------------\n",
            "\u001b[32;1mEarly stopping at step 13 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |               5 |\n",
            "|      AverageEpRet |           -53.9 |\n",
            "|          StdEpRet |            44.7 |\n",
            "|          MaxEpRet |            23.9 |\n",
            "|          MinEpRet |            -191 |\n",
            "|             EpLen |             119 |\n",
            "|      AverageVVals |           -41.2 |\n",
            "|          StdVVals |            7.91 |\n",
            "|          MaxVVals |           -26.2 |\n",
            "|          MinVVals |            -114 |\n",
            "| TotalEnvInteracts |           3e+04 |\n",
            "|            LossPi |       -1.95e-08 |\n",
            "|             LossV |        1.39e+03 |\n",
            "|       DeltaLossPi |        -0.00896 |\n",
            "|        DeltaLossV |            -157 |\n",
            "|           Entropy |            1.28 |\n",
            "|                KL |          0.0158 |\n",
            "|          ClipFrac |           0.338 |\n",
            "|          StopIter |              13 |\n",
            "|              Time |            33.4 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 111 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               6 |\n",
            "|      AverageEpRet |            -118 |\n",
            "|          StdEpRet |             114 |\n",
            "|          MaxEpRet |            24.7 |\n",
            "|          MinEpRet |            -472 |\n",
            "|             EpLen |             169 |\n",
            "|      AverageVVals |           -37.6 |\n",
            "|          StdVVals |            16.9 |\n",
            "|          MaxVVals |           -18.4 |\n",
            "|          MinVVals |            -127 |\n",
            "| TotalEnvInteracts |         3.5e+04 |\n",
            "|            LossPi |       -1.72e-08 |\n",
            "|             LossV |        3.89e+03 |\n",
            "|       DeltaLossPi |          -0.018 |\n",
            "|        DeltaLossV |            -574 |\n",
            "|           Entropy |            1.23 |\n",
            "|                KL |          0.0123 |\n",
            "|          ClipFrac |           0.105 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            39.8 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 46 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               7 |\n",
            "|      AverageEpRet |            -118 |\n",
            "|          StdEpRet |            98.5 |\n",
            "|          MaxEpRet |              36 |\n",
            "|          MinEpRet |            -426 |\n",
            "|             EpLen |             191 |\n",
            "|      AverageVVals |           -48.4 |\n",
            "|          StdVVals |            15.5 |\n",
            "|          MaxVVals |           -28.2 |\n",
            "|          MinVVals |            -207 |\n",
            "| TotalEnvInteracts |           4e+04 |\n",
            "|            LossPi |       -6.68e-09 |\n",
            "|             LossV |        2.04e+03 |\n",
            "|       DeltaLossPi |         -0.0171 |\n",
            "|        DeltaLossV |            -188 |\n",
            "|           Entropy |             1.2 |\n",
            "|                KL |          0.0149 |\n",
            "|          ClipFrac |            0.17 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            46.2 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 111 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               8 |\n",
            "|      AverageEpRet |            -146 |\n",
            "|          StdEpRet |              92 |\n",
            "|          MaxEpRet |           -5.71 |\n",
            "|          MinEpRet |            -302 |\n",
            "|             EpLen |             288 |\n",
            "|      AverageVVals |           -45.8 |\n",
            "|          StdVVals |            16.6 |\n",
            "|          MaxVVals |           -23.7 |\n",
            "|          MinVVals |            -237 |\n",
            "| TotalEnvInteracts |         4.5e+04 |\n",
            "|            LossPi |        1.33e-08 |\n",
            "|             LossV |         1.9e+03 |\n",
            "|       DeltaLossPi |         -0.0143 |\n",
            "|        DeltaLossV |            -550 |\n",
            "|           Entropy |            1.16 |\n",
            "|                KL |         0.00631 |\n",
            "|          ClipFrac |           0.113 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            53.9 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 818 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |               9 |\n",
            "|      AverageEpRet |            -103 |\n",
            "|          StdEpRet |            80.5 |\n",
            "|          MaxEpRet |            26.2 |\n",
            "|          MinEpRet |            -224 |\n",
            "|             EpLen |             232 |\n",
            "|      AverageVVals |             -45 |\n",
            "|          StdVVals |            18.1 |\n",
            "|          MaxVVals |             -20 |\n",
            "|          MinVVals |            -187 |\n",
            "| TotalEnvInteracts |           5e+04 |\n",
            "|            LossPi |        1.42e-08 |\n",
            "|             LossV |        1.51e+03 |\n",
            "|       DeltaLossPi |         -0.0173 |\n",
            "|        DeltaLossV |            -266 |\n",
            "|           Entropy |            1.15 |\n",
            "|                KL |          0.0126 |\n",
            "|          ClipFrac |            0.12 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            60.7 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 157 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              10 |\n",
            "|      AverageEpRet |           -56.5 |\n",
            "|          StdEpRet |              56 |\n",
            "|          MaxEpRet |            36.3 |\n",
            "|          MinEpRet |            -161 |\n",
            "|             EpLen |             484 |\n",
            "|      AverageVVals |           -30.1 |\n",
            "|          StdVVals |            10.9 |\n",
            "|          MaxVVals |           -13.7 |\n",
            "|          MinVVals |            -130 |\n",
            "| TotalEnvInteracts |         5.5e+04 |\n",
            "|            LossPi |        9.82e-09 |\n",
            "|             LossV |        1.31e+03 |\n",
            "|       DeltaLossPi |          -0.012 |\n",
            "|        DeltaLossV |            -365 |\n",
            "|           Entropy |            1.14 |\n",
            "|                KL |         0.00561 |\n",
            "|          ClipFrac |          0.0928 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            72.3 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 709 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              11 |\n",
            "|      AverageEpRet |            -157 |\n",
            "|          StdEpRet |             107 |\n",
            "|          MaxEpRet |           0.328 |\n",
            "|          MinEpRet |            -317 |\n",
            "|             EpLen |             477 |\n",
            "|      AverageVVals |           -20.4 |\n",
            "|          StdVVals |            13.2 |\n",
            "|          MaxVVals |           -5.69 |\n",
            "|          MinVVals |            -130 |\n",
            "| TotalEnvInteracts |           6e+04 |\n",
            "|            LossPi |       -2.48e-08 |\n",
            "|             LossV |        2.01e+03 |\n",
            "|       DeltaLossPi |          -0.013 |\n",
            "|        DeltaLossV |            -714 |\n",
            "|           Entropy |            1.15 |\n",
            "|                KL |         0.00483 |\n",
            "|          ClipFrac |          0.0816 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            81.4 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 312 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              12 |\n",
            "|      AverageEpRet |           -63.9 |\n",
            "|          StdEpRet |            55.9 |\n",
            "|          MaxEpRet |           -1.26 |\n",
            "|          MinEpRet |            -161 |\n",
            "|             EpLen |             586 |\n",
            "|      AverageVVals |           -35.6 |\n",
            "|          StdVVals |              19 |\n",
            "|          MaxVVals |           -4.77 |\n",
            "|          MinVVals |           -98.9 |\n",
            "| TotalEnvInteracts |         6.5e+04 |\n",
            "|            LossPi |       -3.78e-08 |\n",
            "|             LossV |        1.09e+03 |\n",
            "|       DeltaLossPi |         -0.0195 |\n",
            "|        DeltaLossV |            -325 |\n",
            "|           Entropy |            1.13 |\n",
            "|                KL |          0.0102 |\n",
            "|          ClipFrac |           0.169 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |            90.9 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 354 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              13 |\n",
            "|      AverageEpRet |           -67.7 |\n",
            "|          StdEpRet |             108 |\n",
            "|          MaxEpRet |            62.2 |\n",
            "|          MinEpRet |            -186 |\n",
            "|             EpLen |             774 |\n",
            "|      AverageVVals |           -12.1 |\n",
            "|          StdVVals |              11 |\n",
            "|          MaxVVals |            4.18 |\n",
            "|          MinVVals |           -60.4 |\n",
            "| TotalEnvInteracts |           7e+04 |\n",
            "|            LossPi |       -7.32e-09 |\n",
            "|             LossV |             523 |\n",
            "|       DeltaLossPi |         -0.0162 |\n",
            "|        DeltaLossV |            -235 |\n",
            "|           Entropy |            1.13 |\n",
            "|                KL |         0.00998 |\n",
            "|          ClipFrac |           0.182 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             102 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 188 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              14 |\n",
            "|      AverageEpRet |           -49.2 |\n",
            "|          StdEpRet |             134 |\n",
            "|          MaxEpRet |            72.2 |\n",
            "|          MinEpRet |            -331 |\n",
            "|             EpLen |             802 |\n",
            "|      AverageVVals |           -6.75 |\n",
            "|          StdVVals |            16.7 |\n",
            "|          MaxVVals |            13.3 |\n",
            "|          MinVVals |            -139 |\n",
            "| TotalEnvInteracts |         7.5e+04 |\n",
            "|            LossPi |        6.01e-09 |\n",
            "|             LossV |             509 |\n",
            "|       DeltaLossPi |          -0.016 |\n",
            "|        DeltaLossV |           -71.7 |\n",
            "|           Entropy |            1.15 |\n",
            "|                KL |         0.00941 |\n",
            "|          ClipFrac |           0.112 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             113 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 946 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              15 |\n",
            "|      AverageEpRet |           -22.3 |\n",
            "|          StdEpRet |            31.4 |\n",
            "|          MaxEpRet |            32.1 |\n",
            "|          MinEpRet |           -63.9 |\n",
            "|             EpLen |             811 |\n",
            "|      AverageVVals |           0.963 |\n",
            "|          StdVVals |            12.6 |\n",
            "|          MaxVVals |            19.2 |\n",
            "|          MinVVals |             -69 |\n",
            "| TotalEnvInteracts |           8e+04 |\n",
            "|            LossPi |       -2.43e-09 |\n",
            "|             LossV |             310 |\n",
            "|       DeltaLossPi |         -0.0141 |\n",
            "|        DeltaLossV |           -77.4 |\n",
            "|           Entropy |            1.13 |\n",
            "|                KL |         0.00681 |\n",
            "|          ClipFrac |           0.103 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             126 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              16 |\n",
            "|      AverageEpRet |              43 |\n",
            "|          StdEpRet |            17.9 |\n",
            "|          MaxEpRet |            67.9 |\n",
            "|          MinEpRet |            14.8 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |           -7.45 |\n",
            "|          StdVVals |            8.84 |\n",
            "|          MaxVVals |            7.99 |\n",
            "|          MinVVals |           -47.2 |\n",
            "| TotalEnvInteracts |         8.5e+04 |\n",
            "|            LossPi |        1.33e-08 |\n",
            "|             LossV |             296 |\n",
            "|       DeltaLossPi |         -0.0113 |\n",
            "|        DeltaLossV |            -142 |\n",
            "|           Entropy |            1.18 |\n",
            "|                KL |         0.00921 |\n",
            "|          ClipFrac |             0.1 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             139 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              17 |\n",
            "|      AverageEpRet |            72.3 |\n",
            "|          StdEpRet |            22.8 |\n",
            "|          MaxEpRet |            96.3 |\n",
            "|          MinEpRet |            40.9 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |          -0.791 |\n",
            "|          StdVVals |            15.4 |\n",
            "|          MaxVVals |            25.1 |\n",
            "|          MinVVals |           -29.6 |\n",
            "| TotalEnvInteracts |           9e+04 |\n",
            "|            LossPi |       -1.12e-08 |\n",
            "|             LossV |            93.7 |\n",
            "|       DeltaLossPi |        -0.00988 |\n",
            "|        DeltaLossV |           -26.3 |\n",
            "|           Entropy |             1.2 |\n",
            "|                KL |          0.0105 |\n",
            "|          ClipFrac |           0.116 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             152 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 587 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              18 |\n",
            "|      AverageEpRet |            43.7 |\n",
            "|          StdEpRet |            30.6 |\n",
            "|          MaxEpRet |              82 |\n",
            "|          MinEpRet |           0.385 |\n",
            "|             EpLen |             883 |\n",
            "|      AverageVVals |            6.87 |\n",
            "|          StdVVals |            15.6 |\n",
            "|          MaxVVals |            31.1 |\n",
            "|          MinVVals |           -29.9 |\n",
            "| TotalEnvInteracts |         9.5e+04 |\n",
            "|            LossPi |       -2.41e-08 |\n",
            "|             LossV |             215 |\n",
            "|       DeltaLossPi |        -0.00941 |\n",
            "|        DeltaLossV |           -60.6 |\n",
            "|           Entropy |            1.16 |\n",
            "|                KL |         0.00963 |\n",
            "|          ClipFrac |           0.068 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             164 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 332 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              19 |\n",
            "|      AverageEpRet |              13 |\n",
            "|          StdEpRet |            83.3 |\n",
            "|          MaxEpRet |              78 |\n",
            "|          MinEpRet |            -147 |\n",
            "|             EpLen |             934 |\n",
            "|      AverageVVals |            2.49 |\n",
            "|          StdVVals |            11.5 |\n",
            "|          MaxVVals |            21.2 |\n",
            "|          MinVVals |           -26.9 |\n",
            "| TotalEnvInteracts |           1e+05 |\n",
            "|            LossPi |       -1.31e-08 |\n",
            "|             LossV |             277 |\n",
            "|       DeltaLossPi |         -0.0105 |\n",
            "|        DeltaLossV |           -55.9 |\n",
            "|           Entropy |            1.13 |\n",
            "|                KL |          0.0057 |\n",
            "|          ClipFrac |          0.0746 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             177 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 137 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              20 |\n",
            "|      AverageEpRet |            10.6 |\n",
            "|          StdEpRet |             101 |\n",
            "|          MaxEpRet |             111 |\n",
            "|          MinEpRet |            -183 |\n",
            "|             EpLen |             973 |\n",
            "|      AverageVVals |          -0.485 |\n",
            "|          StdVVals |            11.6 |\n",
            "|          MaxVVals |            15.8 |\n",
            "|          MinVVals |           -51.8 |\n",
            "| TotalEnvInteracts |        1.05e+05 |\n",
            "|            LossPi |         8.3e-09 |\n",
            "|             LossV |             290 |\n",
            "|       DeltaLossPi |         -0.0128 |\n",
            "|        DeltaLossV |           -38.3 |\n",
            "|           Entropy |             1.1 |\n",
            "|                KL |         0.00534 |\n",
            "|          ClipFrac |          0.0584 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             187 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              21 |\n",
            "|      AverageEpRet |            58.5 |\n",
            "|          StdEpRet |            36.8 |\n",
            "|          MaxEpRet |              88 |\n",
            "|          MinEpRet |           -13.5 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            2.88 |\n",
            "|          StdVVals |            9.34 |\n",
            "|          MaxVVals |            18.8 |\n",
            "|          MinVVals |           -28.8 |\n",
            "| TotalEnvInteracts |         1.1e+05 |\n",
            "|            LossPi |         4.4e-09 |\n",
            "|             LossV |             117 |\n",
            "|       DeltaLossPi |         -0.0117 |\n",
            "|        DeltaLossV |           -20.5 |\n",
            "|           Entropy |             1.1 |\n",
            "|                KL |         0.00631 |\n",
            "|          ClipFrac |           0.107 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             200 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 553 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              22 |\n",
            "|      AverageEpRet |            78.5 |\n",
            "|          StdEpRet |            43.1 |\n",
            "|          MaxEpRet |             129 |\n",
            "|          MinEpRet |             9.8 |\n",
            "|             EpLen |             889 |\n",
            "|      AverageVVals |            3.47 |\n",
            "|          StdVVals |            7.98 |\n",
            "|          MaxVVals |            23.4 |\n",
            "|          MinVVals |           -25.6 |\n",
            "| TotalEnvInteracts |        1.15e+05 |\n",
            "|            LossPi |         2.5e-09 |\n",
            "|             LossV |             229 |\n",
            "|       DeltaLossPi |         -0.0102 |\n",
            "|        DeltaLossV |           -33.6 |\n",
            "|           Entropy |            1.09 |\n",
            "|                KL |         0.00774 |\n",
            "|          ClipFrac |          0.0852 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             210 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              23 |\n",
            "|      AverageEpRet |            69.5 |\n",
            "|          StdEpRet |            54.7 |\n",
            "|          MaxEpRet |             141 |\n",
            "|          MinEpRet |           -9.96 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |           0.826 |\n",
            "|          StdVVals |            10.3 |\n",
            "|          MaxVVals |            27.2 |\n",
            "|          MinVVals |           -31.7 |\n",
            "| TotalEnvInteracts |         1.2e+05 |\n",
            "|            LossPi |       -7.76e-09 |\n",
            "|             LossV |            74.5 |\n",
            "|       DeltaLossPi |         -0.0115 |\n",
            "|        DeltaLossV |             -24 |\n",
            "|           Entropy |            1.07 |\n",
            "|                KL |         0.00833 |\n",
            "|          ClipFrac |           0.102 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             222 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 132 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              24 |\n",
            "|      AverageEpRet |            32.6 |\n",
            "|          StdEpRet |            57.3 |\n",
            "|          MaxEpRet |            87.8 |\n",
            "|          MinEpRet |           -71.5 |\n",
            "|             EpLen |             974 |\n",
            "|      AverageVVals |            4.89 |\n",
            "|          StdVVals |            7.76 |\n",
            "|          MaxVVals |              32 |\n",
            "|          MinVVals |             -12 |\n",
            "| TotalEnvInteracts |        1.25e+05 |\n",
            "|            LossPi |       -6.14e-09 |\n",
            "|             LossV |             162 |\n",
            "|       DeltaLossPi |         -0.0124 |\n",
            "|        DeltaLossV |           -31.5 |\n",
            "|           Entropy |            1.06 |\n",
            "|                KL |         0.00788 |\n",
            "|          ClipFrac |          0.0944 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             236 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              25 |\n",
            "|      AverageEpRet |            91.2 |\n",
            "|          StdEpRet |            32.2 |\n",
            "|          MaxEpRet |             143 |\n",
            "|          MinEpRet |            55.1 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            3.88 |\n",
            "|          StdVVals |            6.65 |\n",
            "|          MaxVVals |            33.3 |\n",
            "|          MinVVals |           -14.4 |\n",
            "| TotalEnvInteracts |         1.3e+05 |\n",
            "|            LossPi |        1.22e-08 |\n",
            "|             LossV |            66.4 |\n",
            "|       DeltaLossPi |         -0.0136 |\n",
            "|        DeltaLossV |           -37.9 |\n",
            "|           Entropy |            1.06 |\n",
            "|                KL |          0.0113 |\n",
            "|          ClipFrac |           0.146 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             249 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              26 |\n",
            "|      AverageEpRet |            86.1 |\n",
            "|          StdEpRet |            5.88 |\n",
            "|          MaxEpRet |            92.9 |\n",
            "|          MinEpRet |            78.4 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            4.16 |\n",
            "|          StdVVals |            9.05 |\n",
            "|          MaxVVals |              26 |\n",
            "|          MinVVals |           -12.5 |\n",
            "| TotalEnvInteracts |        1.35e+05 |\n",
            "|            LossPi |        5.65e-09 |\n",
            "|             LossV |            42.1 |\n",
            "|       DeltaLossPi |        -0.00974 |\n",
            "|        DeltaLossV |           -16.6 |\n",
            "|           Entropy |            1.07 |\n",
            "|                KL |          0.0073 |\n",
            "|          ClipFrac |          0.0808 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             261 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 222 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              27 |\n",
            "|      AverageEpRet |             110 |\n",
            "|          StdEpRet |            46.5 |\n",
            "|          MaxEpRet |             202 |\n",
            "|          MinEpRet |            74.5 |\n",
            "|             EpLen |             956 |\n",
            "|      AverageVVals |            6.65 |\n",
            "|          StdVVals |              10 |\n",
            "|          MaxVVals |            41.5 |\n",
            "|          MinVVals |           -6.96 |\n",
            "| TotalEnvInteracts |         1.4e+05 |\n",
            "|            LossPi |       -6.82e-10 |\n",
            "|             LossV |             128 |\n",
            "|       DeltaLossPi |         -0.0107 |\n",
            "|        DeltaLossV |           -51.1 |\n",
            "|           Entropy |               1 |\n",
            "|                KL |          0.0108 |\n",
            "|          ClipFrac |          0.0286 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             273 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              28 |\n",
            "|      AverageEpRet |            97.6 |\n",
            "|          StdEpRet |              20 |\n",
            "|          MaxEpRet |             125 |\n",
            "|          MinEpRet |            76.7 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            6.99 |\n",
            "|          StdVVals |            10.1 |\n",
            "|          MaxVVals |              49 |\n",
            "|          MinVVals |           -10.2 |\n",
            "| TotalEnvInteracts |        1.45e+05 |\n",
            "|            LossPi |       -8.35e-09 |\n",
            "|             LossV |            33.2 |\n",
            "|       DeltaLossPi |        -0.00952 |\n",
            "|        DeltaLossV |           -12.4 |\n",
            "|           Entropy |           0.998 |\n",
            "|                KL |         0.00856 |\n",
            "|          ClipFrac |          0.0936 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             286 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 420 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              29 |\n",
            "|      AverageEpRet |            36.1 |\n",
            "|          StdEpRet |            73.5 |\n",
            "|          MaxEpRet |             116 |\n",
            "|          MinEpRet |            -102 |\n",
            "|             EpLen |             916 |\n",
            "|      AverageVVals |            6.48 |\n",
            "|          StdVVals |            9.25 |\n",
            "|          MaxVVals |            38.9 |\n",
            "|          MinVVals |           -10.6 |\n",
            "| TotalEnvInteracts |         1.5e+05 |\n",
            "|            LossPi |        6.28e-09 |\n",
            "|             LossV |             266 |\n",
            "|       DeltaLossPi |          -0.012 |\n",
            "|        DeltaLossV |           -69.7 |\n",
            "|           Entropy |            1.01 |\n",
            "|                KL |         0.00771 |\n",
            "|          ClipFrac |          0.0672 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             300 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              30 |\n",
            "|      AverageEpRet |            99.2 |\n",
            "|          StdEpRet |            16.5 |\n",
            "|          MaxEpRet |             120 |\n",
            "|          MinEpRet |            71.4 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            6.16 |\n",
            "|          StdVVals |            9.93 |\n",
            "|          MaxVVals |            44.3 |\n",
            "|          MinVVals |              -6 |\n",
            "| TotalEnvInteracts |        1.55e+05 |\n",
            "|            LossPi |        1.14e-08 |\n",
            "|             LossV |            32.4 |\n",
            "|       DeltaLossPi |        -0.00844 |\n",
            "|        DeltaLossV |           -20.9 |\n",
            "|           Entropy |            1.05 |\n",
            "|                KL |         0.00825 |\n",
            "|          ClipFrac |          0.0542 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             311 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              31 |\n",
            "|      AverageEpRet |            96.3 |\n",
            "|          StdEpRet |            9.82 |\n",
            "|          MaxEpRet |             115 |\n",
            "|          MinEpRet |            87.5 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            6.13 |\n",
            "|          StdVVals |            11.6 |\n",
            "|          MaxVVals |            40.4 |\n",
            "|          MinVVals |           -13.9 |\n",
            "| TotalEnvInteracts |         1.6e+05 |\n",
            "|            LossPi |       -1.41e-08 |\n",
            "|             LossV |            21.9 |\n",
            "|       DeltaLossPi |         -0.0111 |\n",
            "|        DeltaLossV |           -8.68 |\n",
            "|           Entropy |           0.989 |\n",
            "|                KL |          0.0093 |\n",
            "|          ClipFrac |           0.098 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             322 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              32 |\n",
            "|      AverageEpRet |            99.4 |\n",
            "|          StdEpRet |            13.5 |\n",
            "|          MaxEpRet |             120 |\n",
            "|          MinEpRet |            83.3 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            6.81 |\n",
            "|          StdVVals |            10.6 |\n",
            "|          MaxVVals |            40.4 |\n",
            "|          MinVVals |           -7.56 |\n",
            "| TotalEnvInteracts |        1.65e+05 |\n",
            "|            LossPi |       -1.22e-09 |\n",
            "|             LossV |            18.3 |\n",
            "|       DeltaLossPi |        -0.00712 |\n",
            "|        DeltaLossV |           -5.69 |\n",
            "|           Entropy |            1.02 |\n",
            "|                KL |         0.00905 |\n",
            "|          ClipFrac |          0.0776 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             334 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              33 |\n",
            "|      AverageEpRet |             111 |\n",
            "|          StdEpRet |            12.9 |\n",
            "|          MaxEpRet |             130 |\n",
            "|          MinEpRet |            90.4 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            6.94 |\n",
            "|          StdVVals |            11.7 |\n",
            "|          MaxVVals |            42.3 |\n",
            "|          MinVVals |           -5.94 |\n",
            "| TotalEnvInteracts |         1.7e+05 |\n",
            "|            LossPi |       -1.05e-08 |\n",
            "|             LossV |            13.7 |\n",
            "|       DeltaLossPi |        -0.00788 |\n",
            "|        DeltaLossV |            -4.6 |\n",
            "|           Entropy |            1.04 |\n",
            "|                KL |         0.00972 |\n",
            "|          ClipFrac |          0.0234 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             346 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              34 |\n",
            "|      AverageEpRet |             107 |\n",
            "|          StdEpRet |            20.9 |\n",
            "|          MaxEpRet |             143 |\n",
            "|          MinEpRet |            81.7 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            7.68 |\n",
            "|          StdVVals |            12.5 |\n",
            "|          MaxVVals |            53.6 |\n",
            "|          MinVVals |           -6.07 |\n",
            "| TotalEnvInteracts |        1.75e+05 |\n",
            "|            LossPi |        6.41e-09 |\n",
            "|             LossV |            11.3 |\n",
            "|       DeltaLossPi |        -0.00941 |\n",
            "|        DeltaLossV |           -4.74 |\n",
            "|           Entropy |            1.03 |\n",
            "|                KL |          0.0121 |\n",
            "|          ClipFrac |          0.0508 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             358 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              35 |\n",
            "|      AverageEpRet |             130 |\n",
            "|          StdEpRet |            13.9 |\n",
            "|          MaxEpRet |             148 |\n",
            "|          MinEpRet |             110 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |             8.3 |\n",
            "|          StdVVals |              13 |\n",
            "|          MaxVVals |            56.1 |\n",
            "|          MinVVals |            -5.5 |\n",
            "| TotalEnvInteracts |         1.8e+05 |\n",
            "|            LossPi |        2.65e-09 |\n",
            "|             LossV |            12.4 |\n",
            "|       DeltaLossPi |        -0.00883 |\n",
            "|        DeltaLossV |            -4.8 |\n",
            "|           Entropy |           0.938 |\n",
            "|                KL |           0.014 |\n",
            "|          ClipFrac |          0.0604 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             370 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 571 steps.\n",
            "\u001b[32;1mEarly stopping at step 37 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |              36 |\n",
            "|      AverageEpRet |             101 |\n",
            "|          StdEpRet |              60 |\n",
            "|          MaxEpRet |             153 |\n",
            "|          MinEpRet |             -15 |\n",
            "|             EpLen |             886 |\n",
            "|      AverageVVals |            11.8 |\n",
            "|          StdVVals |            13.2 |\n",
            "|          MaxVVals |            64.3 |\n",
            "|          MinVVals |           -4.63 |\n",
            "| TotalEnvInteracts |        1.85e+05 |\n",
            "|            LossPi |        2.12e-09 |\n",
            "|             LossV |             188 |\n",
            "|       DeltaLossPi |        -0.00996 |\n",
            "|        DeltaLossV |           -53.8 |\n",
            "|           Entropy |             0.9 |\n",
            "|                KL |          0.0155 |\n",
            "|          ClipFrac |           0.152 |\n",
            "|          StopIter |              37 |\n",
            "|              Time |             381 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              37 |\n",
            "|      AverageEpRet |             110 |\n",
            "|          StdEpRet |            19.7 |\n",
            "|          MaxEpRet |             124 |\n",
            "|          MinEpRet |              72 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            8.25 |\n",
            "|          StdVVals |            10.5 |\n",
            "|          MaxVVals |            37.4 |\n",
            "|          MinVVals |           -5.96 |\n",
            "| TotalEnvInteracts |         1.9e+05 |\n",
            "|            LossPi |        1.14e-08 |\n",
            "|             LossV |            29.5 |\n",
            "|       DeltaLossPi |         -0.0107 |\n",
            "|        DeltaLossV |           -17.7 |\n",
            "|           Entropy |           0.854 |\n",
            "|                KL |         0.00851 |\n",
            "|          ClipFrac |          0.0724 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             392 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              38 |\n",
            "|      AverageEpRet |             131 |\n",
            "|          StdEpRet |            6.04 |\n",
            "|          MaxEpRet |             139 |\n",
            "|          MinEpRet |             125 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            8.59 |\n",
            "|          StdVVals |            12.4 |\n",
            "|          MaxVVals |            45.9 |\n",
            "|          MinVVals |           -6.45 |\n",
            "| TotalEnvInteracts |        1.95e+05 |\n",
            "|            LossPi |       -2.21e-09 |\n",
            "|             LossV |            15.3 |\n",
            "|       DeltaLossPi |        -0.00743 |\n",
            "|        DeltaLossV |           -5.71 |\n",
            "|           Entropy |           0.869 |\n",
            "|                KL |         0.00494 |\n",
            "|          ClipFrac |          0.0312 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             402 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 642 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              39 |\n",
            "|      AverageEpRet |             100 |\n",
            "|          StdEpRet |            65.2 |\n",
            "|          MaxEpRet |             143 |\n",
            "|          MinEpRet |           -27.4 |\n",
            "|             EpLen |             872 |\n",
            "|      AverageVVals |            12.1 |\n",
            "|          StdVVals |            14.1 |\n",
            "|          MaxVVals |            59.1 |\n",
            "|          MinVVals |           -5.58 |\n",
            "| TotalEnvInteracts |           2e+05 |\n",
            "|            LossPi |       -8.31e-09 |\n",
            "|             LossV |             318 |\n",
            "|       DeltaLossPi |        -0.00926 |\n",
            "|        DeltaLossV |           -91.9 |\n",
            "|           Entropy |           0.815 |\n",
            "|                KL |         0.00694 |\n",
            "|          ClipFrac |             0.1 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             412 |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "|             Epoch |              40 |\n",
            "|      AverageEpRet |             128 |\n",
            "|          StdEpRet |            11.2 |\n",
            "|          MaxEpRet |             150 |\n",
            "|          MinEpRet |             119 |\n",
            "|             EpLen |           1e+03 |\n",
            "|      AverageVVals |            8.11 |\n",
            "|          StdVVals |            11.4 |\n",
            "|          MaxVVals |              48 |\n",
            "|          MinVVals |           -18.9 |\n",
            "| TotalEnvInteracts |        2.05e+05 |\n",
            "|            LossPi |        3.36e-09 |\n",
            "|             LossV |            25.5 |\n",
            "|       DeltaLossPi |        -0.00722 |\n",
            "|        DeltaLossV |           -17.3 |\n",
            "|           Entropy |           0.772 |\n",
            "|                KL |         0.00545 |\n",
            "|          ClipFrac |           0.107 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             423 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 207 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              41 |\n",
            "|      AverageEpRet |             104 |\n",
            "|          StdEpRet |            50.1 |\n",
            "|          MaxEpRet |             167 |\n",
            "|          MinEpRet |            6.59 |\n",
            "|             EpLen |             799 |\n",
            "|      AverageVVals |            9.45 |\n",
            "|          StdVVals |            15.8 |\n",
            "|          MaxVVals |            64.1 |\n",
            "|          MinVVals |           -58.9 |\n",
            "| TotalEnvInteracts |         2.1e+05 |\n",
            "|            LossPi |        1.57e-09 |\n",
            "|             LossV |             390 |\n",
            "|       DeltaLossPi |        -0.00491 |\n",
            "|        DeltaLossV |            -223 |\n",
            "|           Entropy |           0.758 |\n",
            "|                KL |         0.00842 |\n",
            "|          ClipFrac |          0.0564 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             432 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 351 steps.\n",
            "\u001b[32;1mEarly stopping at step 8 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |              42 |\n",
            "|      AverageEpRet |             155 |\n",
            "|          StdEpRet |            48.3 |\n",
            "|          MaxEpRet |             235 |\n",
            "|          MinEpRet |             109 |\n",
            "|             EpLen |             930 |\n",
            "|      AverageVVals |            8.29 |\n",
            "|          StdVVals |            11.1 |\n",
            "|          MaxVVals |              45 |\n",
            "|          MinVVals |           -8.96 |\n",
            "| TotalEnvInteracts |        2.15e+05 |\n",
            "|            LossPi |        1.25e-08 |\n",
            "|             LossV |             243 |\n",
            "|       DeltaLossPi |        -0.00248 |\n",
            "|        DeltaLossV |           -72.2 |\n",
            "|           Entropy |           0.784 |\n",
            "|                KL |          0.0167 |\n",
            "|          ClipFrac |           0.158 |\n",
            "|          StopIter |               8 |\n",
            "|              Time |             442 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 29 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              43 |\n",
            "|      AverageEpRet |             143 |\n",
            "|          StdEpRet |            40.4 |\n",
            "|          MaxEpRet |             226 |\n",
            "|          MinEpRet |             106 |\n",
            "|             EpLen |             828 |\n",
            "|      AverageVVals |              15 |\n",
            "|          StdVVals |            9.09 |\n",
            "|          MaxVVals |              56 |\n",
            "|          MinVVals |            3.66 |\n",
            "| TotalEnvInteracts |         2.2e+05 |\n",
            "|            LossPi |         1.5e-08 |\n",
            "|             LossV |             169 |\n",
            "|       DeltaLossPi |        -0.00469 |\n",
            "|        DeltaLossV |           -52.9 |\n",
            "|           Entropy |           0.792 |\n",
            "|                KL |         0.00222 |\n",
            "|          ClipFrac |          0.0286 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             452 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 819 steps.\n",
            "\u001b[32;1mEarly stopping at step 37 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |              44 |\n",
            "|      AverageEpRet |             141 |\n",
            "|          StdEpRet |            73.7 |\n",
            "|          MaxEpRet |             233 |\n",
            "|          MinEpRet |            1.26 |\n",
            "|             EpLen |             697 |\n",
            "|      AverageVVals |            16.6 |\n",
            "|          StdVVals |            14.5 |\n",
            "|          MaxVVals |            78.5 |\n",
            "|          MinVVals |           -8.66 |\n",
            "| TotalEnvInteracts |        2.25e+05 |\n",
            "|            LossPi |       -4.49e-09 |\n",
            "|             LossV |             425 |\n",
            "|       DeltaLossPi |        -0.00719 |\n",
            "|        DeltaLossV |            -153 |\n",
            "|           Entropy |           0.761 |\n",
            "|                KL |          0.0152 |\n",
            "|          ClipFrac |           0.105 |\n",
            "|          StopIter |              37 |\n",
            "|              Time |             462 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 147 steps.\n",
            "\u001b[32;1mEarly stopping at step 14 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |              45 |\n",
            "|      AverageEpRet |             177 |\n",
            "|          StdEpRet |            97.9 |\n",
            "|          MaxEpRet |             248 |\n",
            "|          MinEpRet |           -15.5 |\n",
            "|             EpLen |             485 |\n",
            "|      AverageVVals |            18.1 |\n",
            "|          StdVVals |              14 |\n",
            "|          MaxVVals |            77.3 |\n",
            "|          MinVVals |           -19.7 |\n",
            "| TotalEnvInteracts |         2.3e+05 |\n",
            "|            LossPi |       -4.47e-10 |\n",
            "|             LossV |        1.13e+03 |\n",
            "|       DeltaLossPi |        -0.00802 |\n",
            "|        DeltaLossV |            -457 |\n",
            "|           Entropy |           0.776 |\n",
            "|                KL |          0.0152 |\n",
            "|          ClipFrac |           0.185 |\n",
            "|          StopIter |              14 |\n",
            "|              Time |             470 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 112 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              46 |\n",
            "|      AverageEpRet |             147 |\n",
            "|          StdEpRet |             106 |\n",
            "|          MaxEpRet |             246 |\n",
            "|          MinEpRet |           -33.5 |\n",
            "|             EpLen |             489 |\n",
            "|      AverageVVals |            33.6 |\n",
            "|          StdVVals |            12.9 |\n",
            "|          MaxVVals |            80.1 |\n",
            "|          MinVVals |           -12.9 |\n",
            "| TotalEnvInteracts |        2.35e+05 |\n",
            "|            LossPi |        3.74e-09 |\n",
            "|             LossV |        1.04e+03 |\n",
            "|       DeltaLossPi |           -0.01 |\n",
            "|        DeltaLossV |            -427 |\n",
            "|           Entropy |           0.789 |\n",
            "|                KL |         0.00948 |\n",
            "|          ClipFrac |           0.136 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             478 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 257 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              47 |\n",
            "|      AverageEpRet |             204 |\n",
            "|          StdEpRet |            29.9 |\n",
            "|          MaxEpRet |             251 |\n",
            "|          MinEpRet |             138 |\n",
            "|             EpLen |             593 |\n",
            "|      AverageVVals |            22.9 |\n",
            "|          StdVVals |            11.7 |\n",
            "|          MaxVVals |            62.3 |\n",
            "|          MinVVals |           -4.85 |\n",
            "| TotalEnvInteracts |         2.4e+05 |\n",
            "|            LossPi |       -6.34e-09 |\n",
            "|             LossV |             550 |\n",
            "|       DeltaLossPi |        -0.00811 |\n",
            "|        DeltaLossV |            -186 |\n",
            "|           Entropy |           0.739 |\n",
            "|                KL |          0.0117 |\n",
            "|          ClipFrac |          0.0916 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             486 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 65 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              48 |\n",
            "|      AverageEpRet |             159 |\n",
            "|          StdEpRet |             121 |\n",
            "|          MaxEpRet |             251 |\n",
            "|          MinEpRet |           -72.4 |\n",
            "|             EpLen |             411 |\n",
            "|      AverageVVals |            33.7 |\n",
            "|          StdVVals |            12.3 |\n",
            "|          MaxVVals |            65.2 |\n",
            "|          MinVVals |           -12.1 |\n",
            "| TotalEnvInteracts |        2.45e+05 |\n",
            "|            LossPi |       -1.49e-08 |\n",
            "|             LossV |         1.2e+03 |\n",
            "|       DeltaLossPi |         -0.0118 |\n",
            "|        DeltaLossV |            -530 |\n",
            "|           Entropy |           0.812 |\n",
            "|                KL |         0.00861 |\n",
            "|          ClipFrac |          0.0396 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             494 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 14 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              49 |\n",
            "|      AverageEpRet |             135 |\n",
            "|          StdEpRet |            71.1 |\n",
            "|          MaxEpRet |             234 |\n",
            "|          MinEpRet |              60 |\n",
            "|             EpLen |             831 |\n",
            "|      AverageVVals |            22.1 |\n",
            "|          StdVVals |            20.7 |\n",
            "|          MaxVVals |            93.2 |\n",
            "|          MinVVals |           -59.5 |\n",
            "| TotalEnvInteracts |         2.5e+05 |\n",
            "|            LossPi |       -4.64e-09 |\n",
            "|             LossV |             695 |\n",
            "|       DeltaLossPi |         -0.0114 |\n",
            "|        DeltaLossV |            -494 |\n",
            "|           Entropy |           0.698 |\n",
            "|                KL |         0.00986 |\n",
            "|          ClipFrac |           0.109 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             504 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 198 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              50 |\n",
            "|      AverageEpRet |             202 |\n",
            "|          StdEpRet |            46.8 |\n",
            "|          MaxEpRet |             247 |\n",
            "|          MinEpRet |            90.5 |\n",
            "|             EpLen |             480 |\n",
            "|      AverageVVals |            22.8 |\n",
            "|          StdVVals |              16 |\n",
            "|          MaxVVals |            61.1 |\n",
            "|          MinVVals |           -77.5 |\n",
            "| TotalEnvInteracts |        2.55e+05 |\n",
            "|            LossPi |       -2.96e-08 |\n",
            "|             LossV |             665 |\n",
            "|       DeltaLossPi |        -0.00646 |\n",
            "|        DeltaLossV |            -364 |\n",
            "|           Entropy |           0.819 |\n",
            "|                KL |         0.00698 |\n",
            "|          ClipFrac |          0.0514 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             512 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 387 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              51 |\n",
            "|      AverageEpRet |             203 |\n",
            "|          StdEpRet |            46.3 |\n",
            "|          MaxEpRet |             248 |\n",
            "|          MinEpRet |            83.1 |\n",
            "|             EpLen |             513 |\n",
            "|      AverageVVals |            37.9 |\n",
            "|          StdVVals |            20.8 |\n",
            "|          MaxVVals |             114 |\n",
            "|          MinVVals |            8.67 |\n",
            "| TotalEnvInteracts |         2.6e+05 |\n",
            "|            LossPi |        6.69e-09 |\n",
            "|             LossV |             272 |\n",
            "|       DeltaLossPi |        -0.00669 |\n",
            "|        DeltaLossV |            -103 |\n",
            "|           Entropy |           0.785 |\n",
            "|                KL |         0.00572 |\n",
            "|          ClipFrac |          0.0562 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             520 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 358 steps.\n",
            "\u001b[32;1mEarly stopping at step 36 due to reaching max kl.\u001b[0m\n",
            "---------------------------------------\n",
            "|             Epoch |              52 |\n",
            "|      AverageEpRet |             188 |\n",
            "|          StdEpRet |            51.4 |\n",
            "|          MaxEpRet |             244 |\n",
            "|          MinEpRet |             101 |\n",
            "|             EpLen |             580 |\n",
            "|      AverageVVals |            39.4 |\n",
            "|          StdVVals |            22.2 |\n",
            "|          MaxVVals |            92.8 |\n",
            "|          MinVVals |          -0.431 |\n",
            "| TotalEnvInteracts |        2.65e+05 |\n",
            "|            LossPi |       -2.74e-08 |\n",
            "|             LossV |             842 |\n",
            "|       DeltaLossPi |        -0.00372 |\n",
            "|        DeltaLossV |            -548 |\n",
            "|           Entropy |           0.733 |\n",
            "|                KL |          0.0157 |\n",
            "|          ClipFrac |           0.242 |\n",
            "|          StopIter |              36 |\n",
            "|              Time |             529 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 258 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              53 |\n",
            "|      AverageEpRet |             201 |\n",
            "|          StdEpRet |            87.3 |\n",
            "|          MaxEpRet |             267 |\n",
            "|          MinEpRet |           -27.6 |\n",
            "|             EpLen |             474 |\n",
            "|      AverageVVals |            34.7 |\n",
            "|          StdVVals |            10.8 |\n",
            "|          MaxVVals |              74 |\n",
            "|          MinVVals |            11.6 |\n",
            "| TotalEnvInteracts |         2.7e+05 |\n",
            "|            LossPi |           7e-09 |\n",
            "|             LossV |             650 |\n",
            "|       DeltaLossPi |        -0.00716 |\n",
            "|        DeltaLossV |            -399 |\n",
            "|           Entropy |           0.761 |\n",
            "|                KL |         0.00686 |\n",
            "|          ClipFrac |            0.05 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             537 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 355 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              54 |\n",
            "|      AverageEpRet |             161 |\n",
            "|          StdEpRet |             104 |\n",
            "|          MaxEpRet |             251 |\n",
            "|          MinEpRet |           -45.9 |\n",
            "|             EpLen |             464 |\n",
            "|      AverageVVals |            24.8 |\n",
            "|          StdVVals |            30.7 |\n",
            "|          MaxVVals |            84.5 |\n",
            "|          MinVVals |            -106 |\n",
            "| TotalEnvInteracts |        2.75e+05 |\n",
            "|            LossPi |        -2.1e-09 |\n",
            "|             LossV |        1.18e+03 |\n",
            "|       DeltaLossPi |        -0.00899 |\n",
            "|        DeltaLossV |            -631 |\n",
            "|           Entropy |           0.734 |\n",
            "|                KL |         0.00688 |\n",
            "|          ClipFrac |          0.0534 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             545 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 126 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              55 |\n",
            "|      AverageEpRet |             218 |\n",
            "|          StdEpRet |            45.4 |\n",
            "|          MaxEpRet |             254 |\n",
            "|          MinEpRet |            96.9 |\n",
            "|             EpLen |             487 |\n",
            "|      AverageVVals |            30.8 |\n",
            "|          StdVVals |            28.8 |\n",
            "|          MaxVVals |            86.6 |\n",
            "|          MinVVals |           -53.1 |\n",
            "| TotalEnvInteracts |         2.8e+05 |\n",
            "|            LossPi |       -6.42e-09 |\n",
            "|             LossV |        1.37e+03 |\n",
            "|       DeltaLossPi |        -0.00588 |\n",
            "|        DeltaLossV |            -848 |\n",
            "|           Entropy |           0.696 |\n",
            "|                KL |         0.00921 |\n",
            "|          ClipFrac |          0.0642 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             553 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 112 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              56 |\n",
            "|      AverageEpRet |             227 |\n",
            "|          StdEpRet |            28.2 |\n",
            "|          MaxEpRet |             262 |\n",
            "|          MinEpRet |             161 |\n",
            "|             EpLen |             407 |\n",
            "|      AverageVVals |            40.2 |\n",
            "|          StdVVals |            15.8 |\n",
            "|          MaxVVals |            86.2 |\n",
            "|          MinVVals |             -14 |\n",
            "| TotalEnvInteracts |        2.85e+05 |\n",
            "|            LossPi |       -1.16e-08 |\n",
            "|             LossV |             321 |\n",
            "|       DeltaLossPi |        -0.00536 |\n",
            "|        DeltaLossV |            -124 |\n",
            "|           Entropy |           0.721 |\n",
            "|                KL |         0.00591 |\n",
            "|          ClipFrac |          0.0314 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             561 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 332 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              57 |\n",
            "|      AverageEpRet |             197 |\n",
            "|          StdEpRet |            70.8 |\n",
            "|          MaxEpRet |             265 |\n",
            "|          MinEpRet |            12.4 |\n",
            "|             EpLen |             467 |\n",
            "|      AverageVVals |            46.5 |\n",
            "|          StdVVals |            17.1 |\n",
            "|          MaxVVals |            86.7 |\n",
            "|          MinVVals |            17.3 |\n",
            "| TotalEnvInteracts |         2.9e+05 |\n",
            "|            LossPi |        1.45e-08 |\n",
            "|             LossV |             721 |\n",
            "|       DeltaLossPi |        -0.00474 |\n",
            "|        DeltaLossV |            -458 |\n",
            "|           Entropy |           0.751 |\n",
            "|                KL |          0.0015 |\n",
            "|          ClipFrac |           0.091 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             569 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 300 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              58 |\n",
            "|      AverageEpRet |             203 |\n",
            "|          StdEpRet |              67 |\n",
            "|          MaxEpRet |             263 |\n",
            "|          MinEpRet |            13.3 |\n",
            "|             EpLen |             427 |\n",
            "|      AverageVVals |            38.3 |\n",
            "|          StdVVals |            19.1 |\n",
            "|          MaxVVals |            90.2 |\n",
            "|          MinVVals |           -2.43 |\n",
            "| TotalEnvInteracts |        2.95e+05 |\n",
            "|            LossPi |        1.34e-09 |\n",
            "|             LossV |             386 |\n",
            "|       DeltaLossPi |        -0.00528 |\n",
            "|        DeltaLossV |            -105 |\n",
            "|           Entropy |           0.787 |\n",
            "|                KL |         0.00525 |\n",
            "|          ClipFrac |          0.0392 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             577 |\n",
            "---------------------------------------\n",
            "Warning: trajectory cut off by epoch at 221 steps.\n",
            "---------------------------------------\n",
            "|             Epoch |              59 |\n",
            "|      AverageEpRet |             211 |\n",
            "|          StdEpRet |            35.9 |\n",
            "|          MaxEpRet |             257 |\n",
            "|          MinEpRet |             145 |\n",
            "|             EpLen |             478 |\n",
            "|      AverageVVals |            46.5 |\n",
            "|          StdVVals |            20.5 |\n",
            "|          MaxVVals |            99.1 |\n",
            "|          MinVVals |            5.43 |\n",
            "| TotalEnvInteracts |           3e+05 |\n",
            "|            LossPi |         2.2e-08 |\n",
            "|             LossV |             768 |\n",
            "|       DeltaLossPi |        -0.00835 |\n",
            "|        DeltaLossV |            -416 |\n",
            "|           Entropy |           0.783 |\n",
            "|                KL |          0.0107 |\n",
            "|          ClipFrac |          0.0534 |\n",
            "|          StopIter |              79 |\n",
            "|              Time |             585 |\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRgF5ews6HAA"
      },
      "source": [
        "Unfortunately, it doesn't seem like the spinup render works easily with Jupyter notebooks or Colab notebooks, but we do want to see the results of your work! Please see if you can do the following:\n",
        "\n",
        "1. download the output folder to your computer\n",
        "2. Install spinup the same way we did earlier in this notebook on your command line\n",
        "3. Run the command below on your command line\n",
        "\n",
        "If not, you can use the `progress.txt` file in the output folder to demonstrate the performance of your algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NbSuUku5sAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1654620c-cd05-446c-fa24-4ce3219ee3d8"
      },
      "source": [
        "!python -m spinup.run test_policy ./output/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Loading from ./output/pyt_save/model.pt.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "\u001b[32;1mLogging data to /tmp/experiments/1605331567/progress.txt\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spinningup/spinup/utils/test_policy.py\", line 153, in <module>\n",
            "    run_policy(env, get_action, args.len, args.episodes, not(args.norender))\n",
            "  File \"/content/spinningup/spinup/utils/test_policy.py\", line 121, in run_policy\n",
            "    env.render()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/core.py\", line 235, in render\n",
            "    return self.env.render(mode, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/envs/box2d/lunar_lander.py\", line 320, in render\n",
            "    from gym.envs.classic_control import rendering\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\", line 27, in <module>\n",
            "    from pyglet.gl import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\", line 244, in <module>\n",
            "    import pyglet.window\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\", line 1880, in <module>\n",
            "    gl._create_shadow_window()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\", line 220, in _create_shadow_window\n",
            "    _shadow_window = Window(width=1, height=1, visible=False)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/window/xlib/__init__.py\", line 165, in __init__\n",
            "    super(XlibWindow, self).__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\", line 570, in __init__\n",
            "    display = pyglet.canvas.get_display()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/canvas/__init__.py\", line 94, in get_display\n",
            "    return Display()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pyglet/canvas/xlib.py\", line 123, in __init__\n",
            "    raise NoSuchDisplayException('Cannot connect to \"%s\"' % name)\n",
            "pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to \"None\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/spinningup/spinup/run.py\", line 243, in <module>\n",
            "    subprocess.check_call(args, env=os.environ)\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 311, in check_call\n",
            "    raise CalledProcessError(retcode, cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '/content/spinningup/spinup/utils/test_policy.py', './output/']' returned non-zero exit status 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4ku0egq6k7D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}